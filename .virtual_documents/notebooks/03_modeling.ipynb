





import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

pd.set_option('display.max_columns', None)


df_scaled = pd.read_csv('../data/processed/processed_data_scaled.csv')
df_unscaled = pd.read_csv('../data/processed/processed_data_unscaled.csv')


df_scaled.head()


df_unscaled.head()








X = df_scaled.drop(['City', 'Country_code'], axis=1)


inertias = []
k_range = range(2, 11)

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=20)
    kmeans.fit(X)
    inertias.append(kmeans.inertia_)

plt.figure(figsize=(6,4))
plt.plot(k_range, inertias, marker='o')
plt.xlabel("Liczba klastrów (k)")
plt.ylabel("Inertia")
plt.title("Metoda łokcia")
plt.show()





sil_scores = []

k_range = range(2, 11)  # te same wartości k
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=50)
    labels = kmeans.fit_predict(X)
    score = silhouette_score(X, labels)
    sil_scores.append(score)

# Tworzymy tabelkę
sil_df_scaled = pd.DataFrame({
    'k': k_range,
    'silhouette_score': sil_scores
})

print(sil_df_scaled)

# Wykres silhouette
plt.figure(figsize=(8,5))
plt.plot(sil_df_scaled['k'], sil_df_scaled['silhouette_score'], marker='o')
plt.ylim(0, 0.25)
plt.xlabel('Liczba klastrów (k)')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score dla różnych k')
plt.grid(True)
plt.show()





# Redukcja do 2 wymiarów
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

k_values = [2, 3, 4, 6, 8, 10]

plt.figure(figsize=(16, 12))
for i, k in enumerate(k_values, 1):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=50)
    labels = kmeans.fit_predict(X)  # używamy oryginalnych, ustandaryzowanych danych
    
    plt.subplot(3, 3, i)
    sns.scatterplot(
        x=X_pca[:,0], 
        y=X_pca[:,1],
        hue=labels,
        palette='tab10',
        s=60,
        alpha=0.8,
        legend=False
    )
    plt.title(f'K-means k={k}')
    plt.xlabel('PCA 1')
    plt.ylabel('PCA 2')
    plt.grid(True)

plt.tight_layout()
plt.show()








k = 3
kmeans = KMeans(n_clusters=k, random_state=42, n_init=50)
labels = kmeans.fit_predict(X)


cluster_df = pd.DataFrame({
    'City': df_scaled['City'],
    'Country_code': df_scaled['Country_code'],
    'cluster': labels
})

# Merge z df_unscaled po identyfikatorach
df_scaled = df_scaled.merge(cluster_df, on=['City', 'Country_code'], how='left')
df_unscaled = df_unscaled.merge(cluster_df, on=['City', 'Country_code'], how='left')


pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

cluster_colors = ['#FF7F0E', '#1F77B4', '#2CA02C']

plt.figure(figsize=(10,7))
for cluster_id, color in enumerate(cluster_colors):
    plt.scatter(
        X_pca[df_scaled['cluster'] == cluster_id, 0],
        X_pca[df_scaled['cluster'] == cluster_id, 1],
        c=color,
        label=f'Cluster {cluster_id}',
        edgecolor='k',
        s=60,
        alpha=0.8
    )

plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.title('Wizualizacja K-means (k=3)')
plt.legend(title='Cluster')
plt.grid(True)
plt.show()


cluster_summary = df_unscaled.drop(['City', 'Country_code'], axis=1).groupby('cluster').mean()
print(cluster_summary)


# df_unscaled: nieustandaryzowane dane z kolumną 'cluster' i 'Country_code'
country_counts = df_unscaled.groupby(['Country_code', 'cluster']).size().unstack(fill_value=0)


total_cities = country_counts.sum(axis=1)
countries_large = total_cities[total_cities > 20].index
country_counts = country_counts.loc[countries_large]

# konwersja na procenty
country_perc = country_counts.div(country_counts.sum(axis=1), axis=0) * 100

country_perc.plot(
    kind='barh',
    stacked=True,
    figsize=(12,8),
    color=cluster_colors,
    edgecolor='k'
)

plt.xlabel('Procent miast w klastrach')
plt.ylabel('Country_code')
plt.title('Rozkład procentowy miast w klastrach (tylko kraje >30 miast)')
plt.legend(title='Cluster', loc='lower right')
plt.show()


# Funkcja do wyciągnięcia top N miast w danym klastrze
def top_n_cities(df, cluster_col='cluster', city_col='City', pop_col='Population', n=30):
    top_cities = (
        df.sort_values([cluster_col, pop_col], ascending=[True, False])
          .groupby(cluster_col)[city_col]
          .head(n)
          .reset_index(drop=True)
    )
    return top_cities

# Tworzymy słownik z listami top miast dla każdego klastra
clusters = sorted(df_unscaled['cluster'].unique())
top_cities_dict = {
    f'Cluster {c}': df_unscaled[df_unscaled['cluster']==c]
                    .sort_values('Population', ascending=False)['City']
                    .head(30)
                    .reset_index(drop=True)
    for c in clusters
}

# Tworzymy finalny DataFrame
top_cities_df = pd.DataFrame(top_cities_dict)

# Wyświetlamy
top_cities_df






