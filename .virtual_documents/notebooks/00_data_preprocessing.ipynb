import numpy as np
import pandas as pd

pd.set_option('display.max_columns', None)


def load_latest_indicator(path, indicator_name, value_col_name):
    """
    Wczytuje najnowsze dostępne dane dla jednego wskaźnika z pliku CSV.
    Pomija wiersze z break-in-time-series (OBS_FLAG='b') i brakujące wartości.
    
    Args:
        path (str): ścieżka do pliku CSV
        indicator_name (str): nazwa wskaźnika w kolumnie 'Urban audit indicator'
        value_col_name (str): nowa nazwa kolumny z wartościami
    
    Returns:
        pd.DataFrame: DataFrame z kolumnami ['Geopolitical entity (declaring)', value_col_name]
    """
    df = pd.read_csv(path, delimiter=',')
    df = df[df['Urban audit indicator'] == indicator_name].copy()

    # Pomijamy break-in-time-series i brakujące wartości
    if 'OBS_FLAG' in df.columns:
        df = df[df['OBS_FLAG'] != 'b']
    df = df.dropna(subset=['OBS_VALUE'])

    # Sortujemy malejąco po roku i wybieramy najnowszy wiersz dla każdego miasta
    df = df.sort_values(['Geopolitical entity (declaring)', 'TIME_PERIOD'], ascending=[True, False])
    df = df.drop_duplicates(subset=['Geopolitical entity (declaring)'], keep='first')

    # Zmieniamy nazwę kolumny z wartościami
    return df[['Geopolitical entity (declaring)', 'OBS_VALUE']].rename(columns={'OBS_VALUE': value_col_name})


def load_latest_indicators_wide(
    path,
    indicators,
    indicator_col='Urban audit indicator',
    entity_col='Geopolitical entity (declaring)',
    time_col='TIME_PERIOD',
    value_col='OBS_VALUE',
    obs_flag_col='OBS_FLAG',
    drop_obs_flag_value='b',
    low_memory=False,
    rename_map=None
):
    """
    Wczytuje najnowsze dostępne dane dla wielu wskaźników i zwraca je w szerokim formacie.

    Args:
        path (str): ścieżka do pliku CSV
        indicators (list[str]): lista nazw wskaźników do pobrania
        indicator_col (str): kolumna z nazwą wskaźnika
        entity_col (str): kolumna z nazwą miasta / jednostki
        time_col (str): kolumna z rokiem
        value_col (str): kolumna z wartościami
        obs_flag_col (str): kolumna z flagami obserwacji
        drop_obs_flag_value (str): wartość oznaczająca break-in-time-series
        rename_map (dict): opcjonalna mapa {stara_nazwa: nowa_nazwa}

    Returns:
        pd.DataFrame: jeden wiersz na miasto, kolumny = wskaźniki
    """
    df = pd.read_csv(path, delimiter=',')

    # wybór wskaźników
    df = df[df[indicator_col].isin(indicators)]

    # czyszczenie danych
    if obs_flag_col in df.columns:
        df = df[df[obs_flag_col] != drop_obs_flag_value]
    df = df.dropna(subset=[value_col])

    # najnowsze dane dla miasto × wskaźnik
    df = df.sort_values(
        [entity_col, indicator_col, time_col],
        ascending=[True, True, False]
    )
    df = df.drop_duplicates(
        subset=[entity_col, indicator_col],
        keep='first'
    )

    # pivot do wide
    df = df.pivot(
        index=entity_col,
        columns=indicator_col,
        values=value_col
    ).reset_index()

    # opcjonalne czytelne nazwy kolumn
    if rename_map is not None:
        df = df.rename(columns=rename_map)

    return df



def add_feature(df, feature_df):
    """
    Dołącza dodatkowe dane (feature) do głównego DataFrame po nazwach miast.
    
    Args:
        df (pd.DataFrame): główny DataFrame
        feature_df (pd.DataFrame): DataFrame z dodatkowymi kolumnami do połączenia
    
    Returns:
        pd.DataFrame: zaktualizowany główny DataFrame
    """
    return df.merge(
        feature_df,
        on='Geopolitical entity (declaring)',
        how='left'
    )





# Wczytanie wszystkich danych o populacji
pop_total = pd.read_csv('../data/raw/01_population.csv', delimiter=',')

# Wybór wierszy z całkowitą populacją i pominięcie break-in-time-series
pop_total = pop_total[
    (pop_total['Urban audit indicator'] == 'Population on the 1st of January, total') &
    (pop_total['OBS_FLAG'] != 'b')
]

# Sortowanie malejąco po roku i wybór najnowszych danych dla każdego miasta
pop_total = pop_total.sort_values(['Geopolitical entity (declaring)', 'TIME_PERIOD'], ascending=[True, False])
pop_latest = pop_total.drop_duplicates(subset=['Geopolitical entity (declaring)'], keep='first')

# Tworzymy główny DataFrame
df = pop_latest[['Geopolitical entity (declaring)', 'OBS_VALUE']].rename(columns={'OBS_VALUE': 'Population'})





age_indicators = [
    'Age dependency ratio (population aged 0-19 and 65 and more to population aged 20-64)',
    'Young-age dependency ratio (population aged 0-19 to population 20-64 years)',
    'Old age dependency ratio (population 65 and over to population 20 to 64 years)',
    'Median population age'
]

age_rename = {
    age_indicators[0]: 'Age_dependency_ratio',
    age_indicators[1]: 'Young_dependency_ratio',
    age_indicators[2]: 'Old_dependency_ratio',
    age_indicators[3]: 'Median_age'
}

age_structure = load_latest_indicators_wide(
    path='../data/raw/02_population_structure.csv',
    indicators=age_indicators,
    rename_map=age_rename
)

df = add_feature(df, age_structure)





foreigners = load_latest_indicator(
    path='../data/raw/03_foreigners.csv',
    indicator_name='Foreigners as a proportion of population',
    value_col_name='Share_foreigners'
)

df = add_feature(df, foreigners)


df





mortality_indicators = [
    'Infant mortality rate (per 1000 live births)',
    'Number of deaths per year under 65 due to diseases of the circulatory or respiratory systems',
    'Crude birth rate (per 1000 inhabitants)',
    'Crude death rate (per 1000 inhabitants)'
]

mortality_rename = {
    'Infant mortality rate (per 1000 live births)': 'Infant_mortality_rate',
    'Number of deaths per year under 65 due to diseases of the circulatory or respiratory systems':
        'Deaths_under_65_circulatory_respiratory',
    'Crude birth rate (per 1000 inhabitants)': 'Crude_birth_rate',
    'Crude death rate (per 1000 inhabitants)': 'Crude_death_rate'
}

mortality = load_latest_indicators_wide(
    path='../data/raw/04_mortality.csv',
    indicators=mortality_indicators,
    rename_map=mortality_rename
)

df = add_feature(df, mortality)


mortality.sort_values('Crude_death_rate', ascending=False)


df['Deaths_under_65_circ_resp_per_100k'] = (
    df['Deaths_under_65_circulatory_respiratory'] / df['Population'] * 100_000
)

df = df.drop('Deaths_under_65_circulatory_respiratory', axis=1)


# po analizie irracjonalnych przypadków wychodzi na to, że prawdopodobnie wprowadzono wartości zgonów na 1 mln zamiast na 1 tys. urodzeń
df['Infant_mortality_rate'] = df['Infant_mortality_rate'].apply(lambda x: x/1000 if x >1000 else x)






